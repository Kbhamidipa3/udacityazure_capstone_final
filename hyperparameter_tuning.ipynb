{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter_tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKTcsVm5HMdK"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "import pandas as pd\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "from azureml.core import Workspace, Dataset\r\n",
        "from azureml.core import Workspace,ScriptRunConfig,Experiment, Run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y8EZ3ohHYKY"
      },
      "source": [
        "**Dataset**\r\n",
        "\r\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6taCP35HY9V"
      },
      "source": [
        "ws = Workspace.from_config()\r\n",
        "experiment_name = 'lv-hyperparameter'\r\n",
        "\r\n",
        "exp=Experiment(ws, experiment_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToMoi387HvoZ"
      },
      "source": [
        "run = exp.start_logging()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9IwEnozHyai"
      },
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# TODO: Create compute cluster\r\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\r\n",
        "# max_nodes should be no greater than 4.\r\n",
        "\r\n",
        "\r\n",
        "   # Choose a name for your CPU cluster\r\n",
        "cpu_cluster_name = \"cpu-cluster\"\r\n",
        "\r\n",
        "   # Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\r\n",
        "                                                              max_nodes=4)\r\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\r\n",
        "\r\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT1PtPvhH79E"
      },
      "source": [
        "**Hyperdrive Configuration**\r\n",
        "\r\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYpj8hQH8tK"
      },
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.train.sklearn import SKLearn\r\n",
        "from azureml.train.dnn import TensorFlow\r\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\r\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\r\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\r\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\r\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, normal, choice\r\n",
        "import os,shutil\r\n",
        "\r\n",
        "\r\n",
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\r\n",
        "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\r\n",
        "\r\n",
        "#TODO: Create the different params that you will be using during training\r\n",
        "param_sampling = RandomParameterSampling( {\r\n",
        "        '--C': choice(0,0.25,0.5,1),\r\n",
        "        '--max_iter': choice(500,1000,5000,10000)\r\n",
        "    }\r\n",
        ")\r\n",
        "\r\n",
        "if \"training\" not in os.listdir():\r\n",
        "    os.mkdir(\"./training\")\r\n",
        "\r\n",
        "script_folder = \"./training\"    \r\n",
        "    \r\n",
        "# Reference: lesson 6.3: copying the training file into the script folder\r\n",
        "shutil.copy('./train.py', script_folder)\r\n",
        "    \r\n",
        "script_params={\r\n",
        "    '--datastore-dir': ws.get_default_datastore().as_mount(),\r\n",
        "}\r\n",
        "\r\n",
        "#TODO: Create your estimator and hyperdrive config\r\n",
        "estimator = SKLearn(source_directory='training', \r\n",
        "                     script_params=script_params,\r\n",
        "                    compute_target=cpu_cluster,\r\n",
        "                    entry_script='train.py',\r\n",
        "                    pip_packages=['joblib']\r\n",
        "                   )\r\n",
        "\r\n",
        "\r\n",
        "hyperdrive_run_config = HyperDriveConfig(estimator = estimator, \r\n",
        "                                            hyperparameter_sampling = param_sampling, \r\n",
        "                                            policy = early_termination_policy,\r\n",
        "                                            primary_metric_name = \"Accuracy\",\r\n",
        "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\r\n",
        "                                            max_total_runs = 20,\r\n",
        "                                            max_concurrent_runs = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt0TCLUMIC0-"
      },
      "source": [
        "**Run Details**\r\n",
        "\r\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\r\n",
        "\r\n",
        "TODO: In the cell below, use the RunDetails widget to show the different experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb3OS9RJIHPi"
      },
      "source": [
        "#TODO: Submit your experiment\r\n",
        "hd_run = exp.submit(hyperdrive_run_config)\r\n",
        "RunDetails(Run(exp, hd_run.id)).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQkQJhYkIK6a"
      },
      "source": [
        "**Best Model**\r\n",
        "\r\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKniI18xILlt"
      },
      "source": [
        "import joblib\r\n",
        "# Get your best run and save the model from that run.\r\n",
        "\r\n",
        "best_run = hd_run.get_best_run_by_primary_metric()\r\n",
        "best_run_metrics = best_run.get_metrics()\r\n",
        "parameter_values = best_run.get_details()['runDefinition']['arguments']\r\n",
        "\r\n",
        "print('Best Run Id: ', best_run.id)\r\n",
        "print('\\n Accuracy:', best_run_metrics['Accuracy'])\r\n",
        "print('\\n learning rate:',parameter_values[3])\r\n",
        "print('\\n keep probability:',parameter_values[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkivyrlni8bJ"
      },
      "source": [
        "**Connect to your workspace - only if reconnect is needed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0jem2Sli6j3"
      },
      "source": [
        "from azureml.core import Workspace\r\n",
        "ws = Workspace.from_config(path=\".file-path/ws_config.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrQBXTEZM0vM"
      },
      "source": [
        "**Save and register the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gvTtQiVMzpW"
      },
      "source": [
        "import joblib\r\n",
        "\r\n",
        "joblib.dump(svm_model_linear, 'model.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP9FgestM87V"
      },
      "source": [
        "from azureml.core import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "\r\n",
        "model = run.register_model(model_name='sklearn-lv-hyper', \r\n",
        "                           model_path='outputs/model.joblib',\r\n",
        "                           model_framework=Model.Framework.SCIKITLEARN,\r\n",
        "                           model_framework_version='0.19.1',\r\n",
        "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpzayz6z6d--"
      },
      "source": [
        "**Writing run()**\r\n",
        "run() is executed every time your model receives a scoring request, and expects the body of the request to be a JSON document with the following structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oSWFSgb6fdU"
      },
      "source": [
        "{\r\n",
        "    \"data\": <model-specific-data-structure>\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HSRFaW16tB6"
      },
      "source": [
        "Load a registered scikit-learn model and score it with numpy data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl3ZO9ME6tVg"
      },
      "source": [
        "import json\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from sklearn.externals import joblib\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_mnist_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "def run(data):\r\n",
        "    try:\r\n",
        "        data = np.array(json.loads(data))\r\n",
        "        result = model.predict(data)\r\n",
        "        # You can return any data type, as long as it is JSON serializable.\r\n",
        "        return result.tolist()\r\n",
        "    except Exception as e:\r\n",
        "        error = str(e)\r\n",
        "        return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBzexaXd8N1x"
      },
      "source": [
        "**Define an inference configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4DZgMeY8Pak"
      },
      "source": [
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "\r\n",
        "env = Environment.get(workspace, \"AzureML-Minimal\").clone(env_name)\r\n",
        "\r\n",
        "for pip_package in [\"scikit-learn\"]:\r\n",
        "    env.python.conda_dependencies.add_pip_package(pip_package)\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='path-to-score.py',\r\n",
        "                                    environment=env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnHF3W3P8do8"
      },
      "source": [
        "**Define a deployment configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZK_N8ej8fX1"
      },
      "source": [
        "from azureml.core.webservice import AciWebservice, AksWebservice, LocalWebservice\r\n",
        "\r\n",
        "Azure Container Instances\tdeployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HrDMa0INaUW"
      },
      "source": [
        "**Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecMJxmjBNcSa"
      },
      "source": [
        "from azureml.core.webservice import LocalWebservice, Webservice\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(port=8890)\r\n",
        "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(service.state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygkoWc2v9dwy"
      },
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js1pU0yA9fjl"
      },
      "source": [
        "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(service.scoring_uri)\r\n",
        "print(service.swagger_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV8llCGW9vpx"
      },
      "source": [
        "You can use Webservice.list to retrieve a list of deployed web services for models in your workspace. You can add filters to narrow the list of information returned. For more information about what can be filtered on, see the Webservice.list reference documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RGhNR1I9mj_"
      },
      "source": [
        "services = Webservice.list(ws)\r\n",
        "print(services[0].scoring_uri)\r\n",
        "print(services[0].swagger_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfyj6ICt92To"
      },
      "source": [
        "If you know the name of the deployed service, you can create a new instance of Webservice, and provide the workspace and service name as parameters. The new object contains information about the deployed service."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wXJnweW9255"
      },
      "source": [
        "service = Webservice(workspace=ws, name='myservice')\r\n",
        "print(service.scoring_uri)\r\n",
        "print(service.swagger_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0hAi35x-DKA"
      },
      "source": [
        "**Authentication for services**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP3OD8i8-FG0"
      },
      "source": [
        "primary, secondary = service.get_keys()\r\n",
        "print(primary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii4l5LA--QpB"
      },
      "source": [
        "**Request data - KLB: update from Swagger docker page**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GEVJ0W-Vqm"
      },
      "source": [
        "{\r\n",
        "    \"data\":\r\n",
        "        [\r\n",
        "            <model-specific-data-structure>\r\n",
        "        ]\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xez5RpZ-ur0"
      },
      "source": [
        "**Call the service (Python)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7CwxUnd_-v48",
        "outputId": "08bf9ae9-4656-4c38-edd5-b22346272d51"
      },
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "# URL for the web service\r\n",
        "scoring_uri = '<your web service URI>'\r\n",
        "# If the service is authenticated, set the key or token\r\n",
        "key = '<your key or token>'\r\n",
        "\r\n",
        "# Two sets of data to score, so we get two results back\r\n",
        "data = {\"data\":\r\n",
        "        [\r\n",
        "            [\r\n",
        "                0.0199132141783263,\r\n",
        "                0.0506801187398187,\r\n",
        "                0.104808689473925,\r\n",
        "                0.0700725447072635,\r\n",
        "                -0.0359677812752396,\r\n",
        "                -0.0266789028311707,\r\n",
        "                -0.0249926566315915,\r\n",
        "                -0.00259226199818282,\r\n",
        "                0.00371173823343597,\r\n",
        "                0.0403433716478807\r\n",
        "            ],\r\n",
        "            [\r\n",
        "                -0.0127796318808497,\r\n",
        "                -0.044641636506989,\r\n",
        "                0.0606183944448076,\r\n",
        "                0.0528581912385822,\r\n",
        "                0.0479653430750293,\r\n",
        "                0.0293746718291555,\r\n",
        "                -0.0176293810234174,\r\n",
        "                0.0343088588777263,\r\n",
        "                0.0702112981933102,\r\n",
        "                0.00720651632920303]\r\n",
        "        ]\r\n",
        "        }\r\n",
        "# Convert to JSON string\r\n",
        "input_data = json.dumps(data)\r\n",
        "\r\n",
        "# Set the content type\r\n",
        "headers = {'Content-Type': 'application/json'}\r\n",
        "# If authentication is enabled, set the authorization header\r\n",
        "headers['Authorization'] = f'Bearer {key}'\r\n",
        "\r\n",
        "# Make the request and display the response\r\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\r\n",
        "print(resp.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MissingSchema",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2ccf0af5564e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Make the request and display the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '<your web service URI>': No schema supplied. Perhaps you meant http://<your web service URI>?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KAwf8iG--2M"
      },
      "source": [
        "**Web service schema (OpenAPI specification)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tUlCwx5_Dk5"
      },
      "source": [
        "{\r\n",
        "    \"swagger\": \"2.0\",\r\n",
        "    \"info\": {\r\n",
        "        \"title\": \"myservice\",\r\n",
        "        \"description\": \"API specification for Azure Machine Learning myservice\",\r\n",
        "        \"version\": \"1.0\"\r\n",
        "    },\r\n",
        "    \"schemes\": [\r\n",
        "        \"https\"\r\n",
        "    ],\r\n",
        "    \"consumes\": [\r\n",
        "        \"application/json\"\r\n",
        "    ],\r\n",
        "    \"produces\": [\r\n",
        "        \"application/json\"\r\n",
        "    ],\r\n",
        "    \"securityDefinitions\": {\r\n",
        "        \"Bearer\": {\r\n",
        "            \"type\": \"apiKey\",\r\n",
        "            \"name\": \"Authorization\",\r\n",
        "            \"in\": \"header\",\r\n",
        "            \"description\": \"For example: Bearer abc123\"\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"paths\": {\r\n",
        "        \"/\": {\r\n",
        "            \"get\": {\r\n",
        "                \"operationId\": \"ServiceHealthCheck\",\r\n",
        "                \"description\": \"Simple health check endpoint to ensure the service is up at any given point.\",\r\n",
        "                \"responses\": {\r\n",
        "                    \"200\": {\r\n",
        "                        \"description\": \"If service is up and running, this response will be returned with the content 'Healthy'\",\r\n",
        "                        \"schema\": {\r\n",
        "                            \"type\": \"string\"\r\n",
        "                        },\r\n",
        "                        \"examples\": {\r\n",
        "                            \"application/json\": \"Healthy\"\r\n",
        "                        }\r\n",
        "                    },\r\n",
        "                    \"default\": {\r\n",
        "                        \"description\": \"The service failed to execute due to an error.\",\r\n",
        "                        \"schema\": {\r\n",
        "                            \"$ref\": \"#/definitions/ErrorResponse\"\r\n",
        "                        }\r\n",
        "                    }\r\n",
        "                }\r\n",
        "            }\r\n",
        "        },\r\n",
        "        \"/score\": {\r\n",
        "            \"post\": {\r\n",
        "                \"operationId\": \"RunMLService\",\r\n",
        "                \"description\": \"Run web service's model and get the prediction output\",\r\n",
        "                \"security\": [\r\n",
        "                    {\r\n",
        "                        \"Bearer\": []\r\n",
        "                    }\r\n",
        "                ],\r\n",
        "                \"parameters\": [\r\n",
        "                    {\r\n",
        "                        \"name\": \"serviceInputPayload\",\r\n",
        "                        \"in\": \"body\",\r\n",
        "                        \"description\": \"The input payload for executing the real-time machine learning service.\",\r\n",
        "                        \"schema\": {\r\n",
        "                            \"$ref\": \"#/definitions/ServiceInput\"\r\n",
        "                        }\r\n",
        "                    }\r\n",
        "                ],\r\n",
        "                \"responses\": {\r\n",
        "                    \"200\": {\r\n",
        "                        \"description\": \"The service processed the input correctly and provided a result prediction, if applicable.\",\r\n",
        "                        \"schema\": {\r\n",
        "                            \"$ref\": \"#/definitions/ServiceOutput\"\r\n",
        "                        }\r\n",
        "                    },\r\n",
        "                    \"default\": {\r\n",
        "                        \"description\": \"The service failed to execute due to an error.\",\r\n",
        "                        \"schema\": {\r\n",
        "                            \"$ref\": \"#/definitions/ErrorResponse\"\r\n",
        "                        }\r\n",
        "                    }\r\n",
        "                }\r\n",
        "            }\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"definitions\": {\r\n",
        "        \"ServiceInput\": {\r\n",
        "            \"type\": \"object\",\r\n",
        "            \"properties\": {\r\n",
        "                \"data\": {\r\n",
        "                    \"type\": \"array\",\r\n",
        "                    \"items\": {\r\n",
        "                        \"type\": \"array\",\r\n",
        "                        \"items\": {\r\n",
        "                            \"type\": \"integer\",\r\n",
        "                            \"format\": \"int64\"\r\n",
        "                        }\r\n",
        "                    }\r\n",
        "                }\r\n",
        "            },\r\n",
        "            \"example\": {\r\n",
        "                \"data\": [\r\n",
        "                    [ 10, 9, 8, 7, 6, 5, 4, 3, 2, 1 ]\r\n",
        "                ]\r\n",
        "            }\r\n",
        "        },\r\n",
        "        \"ServiceOutput\": {\r\n",
        "            \"type\": \"array\",\r\n",
        "            \"items\": {\r\n",
        "                \"type\": \"number\",\r\n",
        "                \"format\": \"double\"\r\n",
        "            },\r\n",
        "            \"example\": [\r\n",
        "                3726.995\r\n",
        "            ]\r\n",
        "        },\r\n",
        "        \"ErrorResponse\": {\r\n",
        "            \"type\": \"object\",\r\n",
        "            \"properties\": {\r\n",
        "                \"status_code\": {\r\n",
        "                    \"type\": \"integer\",\r\n",
        "                    \"format\": \"int32\"\r\n",
        "                },\r\n",
        "                \"message\": {\r\n",
        "                    \"type\": \"string\"\r\n",
        "                }\r\n",
        "            }\r\n",
        "        }\r\n",
        "    }\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5UlQf5_QJv"
      },
      "source": [
        "## Delete resources\r\n",
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYVKbDbJ_fOX"
      },
      "source": [
        "service.delete()\r\n",
        "model.delete()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}