{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from azureml.core.run import Run\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core import Workspace, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-131495\n",
      "aml-quickstarts-131495\n",
      "southcentralus\n",
      "6b4af8be-9931-443e-90f6-c4c34a1f9737\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "\n",
    "web_path ='https://raw.githubusercontent.com/Kbhamidipa3/udacityazure_capstone_final/main/LasVegasTripAdvisorReviews-Dataset.csv'\n",
    "\n",
    "ds = Dataset.Tabular.from_delimited_files(path=web_path)\n",
    "x_df = ds.to_pandas_dataframe()\n",
    "print(x_df.Pool[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    }
   ],
   "source": [
    "def clean_data(data):\n",
    "    # Dict for cleaning data\n",
    "    months = {\"January\":1, \"February\":2, \"March\":3, \"April\":4, \"May\":5, \"June\":6, \"July\":7, \"August\":8, \"September\":9, \"October\":10, \"November\":11, \"December\":12}\n",
    "    weekdays = {\"Monday\":1, \"Tuesday\":2, \"Wednesday\":3, \"Thursday\":4, \"Friday\":5, \"Saturday\":6, \"Sunday\":7}\n",
    "    # The following dictionaries are only used to replace missing information, other data is untouched\n",
    "    country_cont = {\"Australia\":\"Oceania\", \"Brazil\":\"South America\", \"Canada\":\"North America\", \"Denmark\":\"Europe\", \"Finland\":\"Europe\", \"Germany\":\"Europe\", \"Hawaii\":\"North America\", \"India\":\"Asia\", \"Ireland\":\"Europe\", \"Israel\":\"Asia\", \"Japan\":\"Asia\", \"Kuwait\":\"Asia\", \"Mexico\":\"North America\", \"Netherlands\":\"Europe\", \"Norway\":\"Europe\", \"Taiwan\":\"Asia\", \"Thailand\":\"Asia\", \"UK\":\"Europe\", \"USA\":\"North America\", \"Saudi Arabia\":\"Asia\"}\n",
    "    hotel_rooms = {\"The Cromwell\":188, \"Hilton Grand Vacations on the Boulevard\":1228, \"Marriott's Grand Chateau\":643, \"Wyndham Grand Desert\":787}\n",
    "    period_month = {\"Dec-Feb\":\"January\", \"Mar-May\":\"April\", \"Jun-Aug\":\"July\", \"Sep-Nov\":\"October\"}\n",
    "    hotel_day = {\"The Cromwell\":\"Sunday\", \"Hilton Grand Vacations on the Boulevard\":\"Sunday\", \"Marriott's Grand Chateau\":\"Sunday\", \"Wyndham Grand Desert\":\"Sunday\"}\n",
    "    # Clean the data\n",
    "    x_df = data.to_pandas_dataframe()\n",
    "    print(x_df.Pool[0])\n",
    "    x_df.columns = [c.replace(' ', '_') for c in x_df.columns]\n",
    "    # Aligning the data to work as a classification problem\n",
    "    # Redefining \"Score\" to have a value of 1 if score is >=3 and 0 otherwise\n",
    "    x_df[\"Score\"] = x_df.Score.apply(lambda s: 1 if s >= 3 else 0)\n",
    "    # Fill in the missing data\n",
    "    x_df.User_continent_dup = x_df.User_continent.fillna(x_df.User_country)\n",
    "    x_df[\"User_continent_dup\"] = x_df.User_continent_dup.map(country_cont)\n",
    "    x_df.columns = x_df.columns.str.replace('User_continent_dup', 'User_continent')\n",
    "    x_df.columns = x_df.columns.str.replace('Nr._', 'Nr_')\n",
    "    x_df.Nr_rooms_dup = x_df.Nr_rooms.fillna(x_df.Hotel_name)\n",
    "    x_df[\"Nr_rooms_dup\"] = x_df.Nr_rooms_dup.map(hotel_rooms)\n",
    "    x_df.columns = x_df.columns.str.replace('Nr_rooms_dup', 'Nr_rooms')\n",
    "    x_df.Review_month_dup = x_df.Review_month.fillna(x_df.Period_of_stay)\n",
    "    x_df[\"Review_month_dup\"] = x_df.Review_month_dup.map(period_month)\n",
    "    x_df.columns = x_df.columns.str.replace('Review_month_dup', 'Review_month')\n",
    "    x_df.Review_weekday_dup = x_df.Review_weekday.fillna(x_df.Hotel_name)\n",
    "    x_df[\"Review_weekday_dup\"] = x_df.Review_weekday_dup.map(hotel_day)\n",
    "    x_df.columns = x_df.columns.str.replace('Review_weekday_dup', 'Review_weekday')\n",
    "    s = x_df.stack()\n",
    "    x_df = s.unstack()\n",
    "    #Replace blank and negative cells under Member years in a dataframe with random values between 1 and 10\n",
    "    x_df['Member_years'] = x_df['Member_years'].apply(lambda l: l if l>0 else np.random.choice([1, 10]))\n",
    "    # Restoring all entries to their default datatypes    \n",
    "    x_df[['Nr_reviews','Nr_rooms','Nr_hotel_reviews','Member_years','Score', 'Helpful_votes', 'Hotel_stars', 'Nr_reviews']]=x_df[['Nr_reviews','Nr_rooms','Nr_hotel_reviews','Member_years','Score', 'Helpful_votes', 'Hotel_stars', 'Nr_reviews']].astype(np.int64)\n",
    "    x_df.to_csv(\"LV-github-automl.csv\")    \n",
    "    # Replace with one hot encode data\n",
    "    User_countries = pd.get_dummies(x_df.User_country, prefix=\"User_country\")\n",
    "    x_df.drop(\"User_country\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(User_countries)\n",
    "    Stay_periods = pd.get_dummies(x_df.Period_of_stay, prefix=\"Period_of_stay\")\n",
    "    x_df.drop(\"Period_of_stay\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(Stay_periods)\n",
    "    Traveler_types = pd.get_dummies(x_df.Traveler_type, prefix=\"Traveler_type\")\n",
    "    x_df.drop(\"Traveler_type\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(Traveler_types)\n",
    "    Hotel_names = pd.get_dummies(x_df.Hotel_name, prefix=\"Hotel_name\")\n",
    "    x_df.drop(\"Hotel_name\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(Hotel_names)\n",
    "    User_continents = pd.get_dummies(x_df.User_continent, prefix=\"User_continent\")\n",
    "    x_df.drop(\"User_continent\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(User_continents)\n",
    "    x_df[\"Pool\"] = x_df.Pool.apply(lambda s: 1 if s == \"YES\" else 0)\n",
    "    x_df[\"Gym\"] = x_df.Gym.apply(lambda s: 1 if s == \"YES\" else 0)\n",
    "    x_df[\"Tennis_court\"] = x_df.Tennis_court.apply(lambda s: 1 if s == \"YES\" else 0)\n",
    "    x_df[\"Spa\"] = x_df.Spa.apply(lambda s: 1 if s == \"YES\" else 0)\n",
    "    x_df[\"Casino\"] = x_df.Casino.apply(lambda s: 1 if s == \"YES\" else 0)\n",
    "    x_df[\"Free_internet\"] = x_df.Free_internet.apply(lambda s: 1 if s == \"YES\" else 0)\n",
    "    x_df[\"month\"] = x_df.Review_month.map(months)\n",
    "    x_df[\"weekday\"] = x_df.Review_weekday.map(weekdays)\n",
    "    x_df.drop(\"Review_month\", inplace=True, axis=1)\n",
    "    x_df.drop(\"Review_weekday\", inplace=True, axis=1)\n",
    "    x_df.to_csv(\"LV-github-hypertuning.csv\") \n",
    "    # Separate out the label data from the remainder of the dataframe\n",
    "    y_df = x_df.pop(\"Score\")\n",
    "\n",
    "    return (x_df,y_df)\n",
    "    \n",
    "x, y = clean_data(ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into train and test sets.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
    "\n",
    "run = Run.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric Regularization Strength::\n",
      "0.75\n",
      "Attempted to log scalar metric Max iterations::\n",
      "2000\n",
      "Attempted to log scalar metric Accuracy:\n",
      "0.9126984126984127\n",
      "0.9126984126984127\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Add arguments to script\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--C', type=float, default=0.75, help=\"Inverse of regularization strength. Smaller values cause stronger regularization\")\n",
    "    parser.add_argument('--max_iter', type=int, default=2000, help=\"Maximum number of iterations to converge\")\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[]) #call from notebook\n",
    "\n",
    "\n",
    "    run.log(\"Regularization Strength:\", np.float(args.C))\n",
    "    run.log(\"Max iterations:\", np.int(args.max_iter))\n",
    "\n",
    "    model = LogisticRegression(C=args.C, max_iter=args.max_iter).fit(x_train, y_train)\n",
    "\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    run.log(\"Accuracy\", np.float(accuracy))\n",
    "    print(accuracy)\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    joblib.dump(value=model, filename='outputs/hp_trained_model.pkl')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
